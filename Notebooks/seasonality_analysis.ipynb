{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c302449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 2\n",
      "Python-dotenv could not parse statement starting at line 3\n",
      "Python-dotenv could not parse statement starting at line 4\n",
      "Warning: Ignoring non-Spark config property: fs.azure.account.key.dataintensiveproject.blob.core.windows.net\n",
      "25/04/21 20:08:12 WARN Utils: Your hostname, Rishabhs-Laptop.local resolves to a loopback address: 127.0.0.1; using 192.168.0.179 instead (on interface en0)\n",
      "25/04/21 20:08:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/rishabhsaudagar/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/rishabhsaudagar/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-azure added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a0dc8dc0-e160-4b19-ab17-aecdddf7f319;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/anaconda3/envs/datascience/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.hadoop#hadoop-azure;3.3.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound com.google.guava#guava;27.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.2.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 233ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.2.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   23  |   0   |   0   |   0   ||   23  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a0dc8dc0-e160-4b19-ab17-aecdddf7f319\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 23 already retrieved (0kB/5ms)\n",
      "25/04/21 20:08:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, max as spark_max, countDistinct, sum as spark_sum, datediff, lit, when\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CustomerJourneyAnalysis\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.1\") \\\n",
    "    .config(\"fs.azure.account.key.dataintensiveproject.blob.core.windows.net\", os.getenv(\"AZURE_STORAGE_KEY\")) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ec73e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 20:08:17 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-azure-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: long (nullable = true)\n",
      " |-- InvoiceDate: timestamp_ntz (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- InvoiceYear: integer (nullable = true)\n",
      " |-- InvoiceMonth: integer (nullable = true)\n",
      " |-- InvoiceWeekday: integer (nullable = true)\n",
      " |-- InvoiceHour: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+------------+--------------+-----------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|InvoiceYear|InvoiceMonth|InvoiceWeekday|InvoiceHour|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+------------+--------------+-----------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|       2010|          12|             4|          8|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|       2010|          12|             4|          8|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|       2010|          12|             4|          8|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|       2010|          12|             4|          8|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|       2010|          12|             4|          8|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+-----------+------------+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Path to your Parquet data\n",
    "parquet_path = \"wasbs://retail-data@dataintensiveproject.blob.core.windows.net/clean/retail_cleaned\"\n",
    "\n",
    "# Read the cleaned data\n",
    "df = spark.read.parquet(parquet_path)\n",
    "df.printSchema()\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0701f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------------+\n",
      "|InvoiceYear|InvoiceMonth|        TotalSales|\n",
      "+-----------+------------+------------------+\n",
      "|       2010|          12| 572713.8900000163|\n",
      "|       2011|           1| 569445.0400000077|\n",
      "|       2011|           2| 447137.3500000165|\n",
      "|       2011|           3|  595500.760000013|\n",
      "|       2011|           4| 469200.3610000132|\n",
      "|       2011|           5| 678594.5600000018|\n",
      "|       2011|           6| 661213.6900000116|\n",
      "|       2011|           7| 600091.0110000141|\n",
      "|       2011|           8|  645343.900000009|\n",
      "|       2011|           9| 952838.3819999964|\n",
      "|       2011|          10|1039318.7899999822|\n",
      "|       2011|          11|1161817.3799999433|\n",
      "+-----------+------------+------------------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthly_sales = df.groupBy(\"InvoiceYear\", \"InvoiceMonth\") \\\n",
    "    .agg(spark_sum(col(\"Quantity\") * col(\"UnitPrice\")).alias(\"TotalSales\")) \\\n",
    "    .orderBy(\"InvoiceYear\", \"InvoiceMonth\")\n",
    "\n",
    "monthly_sales.show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4181b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_pd = monthly_sales.toPandas()\n",
    "monthly_sales_pd[\"Month\"] = pd.to_datetime(\n",
    "    monthly_sales_pd[\"InvoiceYear\"].astype(str) + \"-\" + monthly_sales_pd[\"InvoiceMonth\"].astype(str), format=\"%Y-%m\"\n",
    ")\n",
    "monthly_sales_pd = monthly_sales_pd.sort_values(\"Month\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5b03d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(monthly_sales_pd[\"Month\"], monthly_sales_pd[\"TotalSales\"], marker='o')\n",
    "plt.title(\"Monthly Sales Trend\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Total Sales ()\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00029927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Top Performing Months:\n",
      "     InvoiceYear  InvoiceMonth   TotalSales      Month\n",
      "11         2011            11  1161817.380 2011-11-01\n",
      "10         2011            10  1039318.790 2011-10-01\n",
      "9          2011             9   952838.382 2011-09-01\n",
      "\n",
      " Lowest Performing Months:\n",
      "     InvoiceYear  InvoiceMonth  TotalSales      Month\n",
      "2          2011             2  447137.350 2011-02-01\n",
      "4          2011             4  469200.361 2011-04-01\n",
      "12         2011            12  518192.790 2011-12-01\n"
     ]
    }
   ],
   "source": [
    "# Sort to find top and bottom months\n",
    "top_months = monthly_sales_pd.sort_values(\"TotalSales\", ascending=False).head(3)\n",
    "bottom_months = monthly_sales_pd.sort_values(\"TotalSales\", ascending=True).head(3)\n",
    "\n",
    "print(\" Top Performing Months:\\n\", top_months)\n",
    "print(\"\\n Lowest Performing Months:\\n\", bottom_months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c82cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_sales_pd[\"MonthName\"] = monthly_sales_pd[\"Month\"].dt.strftime(\"%b %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25459a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from statsmodels) (1.24.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from statsmodels) (1.10.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from statsmodels) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/datascience/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.0->statsmodels) (1.16.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x must have 2 complete cycles requires 24 observations. x only has 13 observation(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m monthly_sales_pd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRollingMean\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m monthly_sales_pd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotalSales\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      8\u001b[0m monthly_sales_pd[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotalSales\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRollingMean\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mplot(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m), title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonthly Sales with Rolling Average\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mseasonal_decompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonthly_sales_pd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTotalSales\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Plot decomposition\u001b[39;00m\n\u001b[1;32m     14\u001b[0m result\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datascience/lib/python3.8/site-packages/statsmodels/tsa/seasonal.py:171\u001b[0m, in \u001b[0;36mseasonal_decompose\u001b[0;34m(x, model, filt, period, two_sided, extrapolate_trend)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must specify a period or x must be a pandas object with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma PeriodIndex or a DatetimeIndex with a freq not set to None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m         )\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m pfreq:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx must have 2 complete cycles requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m2\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mpfreq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservations. x only has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m observation(s)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m period \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# split weights at ends\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: x must have 2 complete cycles requires 24 observations. x only has 13 observation(s)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Set Month as index for time series\n",
    "monthly_sales_pd[\"RollingMean\"] = monthly_sales_pd[\"TotalSales\"].rolling(window=3, center=True).mean()\n",
    "\n",
    "monthly_sales_pd[[\"TotalSales\", \"RollingMean\"]].plot(figsize=(12, 6), title=\"Monthly Sales with Rolling Average\")\n",
    "\n",
    "\n",
    "result = seasonal_decompose(monthly_sales_pd[\"TotalSales\"], model=\"additive\")\n",
    "\n",
    "# Plot decomposition\n",
    "result.plot()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640c5af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract month names and calculate average sales\n",
    "monthly_avg = monthly_sales_pd.copy()\n",
    "monthly_avg['MonthName'] = monthly_avg.index.strftime('%b')\n",
    "monthly_avg = monthly_avg.groupby(\"MonthName\")[\"TotalSales\"].mean().reindex([\n",
    "    'Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
    "\n",
    "# Plot bar chart\n",
    "monthly_avg.plot(kind='bar', figsize=(10, 5), title='Average Sales by Month', ylabel='Avg Sales ()')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1d671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Ensure TotalPrice is numeric\n",
    "df = df.withColumn(\"TotalPrice\", col(\"UnitPrice\") * col(\"Quantity\"))\n",
    "df = df.withColumn(\"TotalPrice\", col(\"TotalPrice\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7450ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: long (nullable = true)\n",
      " |-- InvoiceDate: timestamp_ntz (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: double (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- InvoiceYear: integer (nullable = true)\n",
      " |-- InvoiceMonth: integer (nullable = true)\n",
      " |-- InvoiceWeekday: integer (nullable = true)\n",
      " |-- InvoiceHour: integer (nullable = true)\n",
      " |-- TotalPrice: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01ad6803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "# Group by weekday\n",
    "weekday_sales = df.groupBy(\"InvoiceWeekday\").agg(_sum(\"TotalPrice\").alias(\"WeekdaySales\")) \\\n",
    "                  .orderBy(\"InvoiceWeekday\")\n",
    "\n",
    "# Convert to pandas for plotting\n",
    "weekday_sales_pd = weekday_sales.toPandas()\n",
    "\n",
    "# Replace numbers with weekday names (optional for readability)\n",
    "weekday_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "weekday_sales_pd[\"InvoiceWeekday\"] = weekday_sales_pd[\"InvoiceWeekday\"].astype(int)\n",
    "weekday_sales_pd[\"WeekdayName\"] = weekday_sales_pd[\"InvoiceWeekday\"].apply(lambda x: weekday_names[x])\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(weekday_sales_pd[\"WeekdayName\"], weekday_sales_pd[\"WeekdaySales\"])\n",
    "plt.title(\"Sales by Weekday\")\n",
    "plt.ylabel(\"Total Sales ()\")\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f340781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 03:53:04 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1971762 ms exceeds timeout 120000 ms\n",
      "25/04/22 03:53:04 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "25/04/22 03:53:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 03:53:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 03:53:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 03:53:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 03:53:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 03:53:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 03:53:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 03:53:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:12:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 04:12:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 04:12:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:12:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:29:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:29:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:45:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:45:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:45:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 04:45:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:02:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:02:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:02:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:02:48 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:02:58 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:02:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:18:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:19:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:19:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 05:37:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 05:37:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 06:00:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 06:00:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 06:00:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 06:00:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 06:16:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 06:16:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 06:16:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 06:16:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 06:17:09 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 06:17:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 06:33:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 06:33:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 07:04:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 07:04:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 07:20:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 07:20:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 07:20:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 07:20:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 07:20:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:20:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:43:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:43:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:44:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:44:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:44:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:44:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:44:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:44:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:59:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:59:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:59:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:59:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:59:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 07:59:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:02:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:02:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:02:22 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:02:22 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:02:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:02:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:02:42 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:02:42 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:02:52 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:02:52 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:18:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:18:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:18:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:18:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:19:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:19:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:19:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:19:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:37:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:37:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:55:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:55:16 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:55:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:55:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:55:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:55:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 08:55:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:55:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:56:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 08:56:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:05:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:05:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:05:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:05:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:05:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:05:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:06:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:14 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:14 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:24 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:24 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:34 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:34 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "25/04/22 09:06:44 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:06:44 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:06:54 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:06:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:07:04 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:07:04 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.179:54919\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "25/04/22 09:07:04 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "# Seasonality\n",
    "df.coalesce(1).write.mode('overwrite').option(\"header\", True).csv(\"PowerBI/monthly_trends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4641dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
